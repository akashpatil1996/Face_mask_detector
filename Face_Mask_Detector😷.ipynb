{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1WHPHab-AabS5sD4heDsAShF47bq2vm7n",
      "authorship_tag": "ABX9TyNsWKuFBhpcLKpbub6lX4wu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akashpatil1996/Face_mask_detector/blob/main/Face_Mask_Detector%F0%9F%98%B7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset from kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "ed5t6yBqMvvP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d omkargurav/face-mask-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP0pEsWANA7e",
        "outputId": "938eb6d8-00fb-43d7-89b7-d69aa1797083"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading face-mask-dataset.zip to /content\n",
            "100% 163M/163M [00:08<00:00, 22.5MB/s]\n",
            "100% 163M/163M [00:08<00:00, 21.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-4pgX4FjBH4R"
      },
      "outputs": [],
      "source": [
        "# Importing required Libraries\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzipping the data\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/face-mask-dataset.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "HiXV3zJkDCgh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the labels and checking the number of images\n",
        "without_mask_files = os.listdir('/content/data/without_mask')\n",
        "with_mask_files = os.listdir('/content/data/with_mask')\n",
        "\n",
        "print(len(with_mask_files), 'images with mask')\n",
        "print(len(without_mask_files), 'images without mask')\n",
        "\n",
        "with_mask_labels = [1]*3725\n",
        "without_mask_labels = [0]*3828"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP3FR965RWmP",
        "outputId": "5f1b9089-60a2-4751-f782-3b5613da38e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3725 images with mask\n",
            "3828 images without mask\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert images to numpy arrays and appending them to a list\n",
        "with_mask_path = '/content/data/with_mask/'\n",
        "without_mask_path = '/content/data/without_mask/'\n",
        "\n",
        "data = []\n",
        "\n",
        "for img_file in with_mask_files:\n",
        "  image = Image.open(with_mask_path + img_file)\n",
        "  image = image.resize((128,128))\n",
        "  image = image.convert('RGB')\n",
        "  image = np.array(image)\n",
        "  data.append(image)\n",
        "\n",
        "\n",
        "for img_file in without_mask_files:\n",
        "  image = Image.open(without_mask_path + img_file)\n",
        "  image = image.resize((128,128))\n",
        "  image = image.convert('RGB')\n",
        "  image = np.array(image)\n",
        "  data.append(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AalJXIpvRPh0",
        "outputId": "8211c93e-8bbd-4e36-a9b9-98f6ef07fda8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/PIL/Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the labels\n",
        "with_mask_labels = [1]*3725\n",
        "without_mask_labels = [0]*3828\n",
        "labels = with_mask_labels + without_mask_labels"
      ],
      "metadata": {
        "id": "u7uv9-h6SZ_Q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting list to numpy array\n",
        "X = np.array(data)\n",
        "y = np.array(labels)\n",
        "print(f'Shape of X: {X.shape}')\n",
        "print(f'Shape of y: {y.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKjkMmSvNkQc",
        "outputId": "a1df0cb6-0914-4cc4-a8b6-c04507340186"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (7553, 128, 128, 3)\n",
            "Shape of y: (7553,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing the data\n",
        "X = X/255"
      ],
      "metadata": {
        "id": "7h49DwM9NlEY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "print(f'Train Data: {X_train.shape}')\n",
        "print(f'Test Data: {X_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCnuuqNlO_Rt",
        "outputId": "e757b3ac-f7f9-4cb4-c7a1-303d7ea2075b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data: (6042, 128, 128, 3)\n",
            "Test Data: (1511, 128, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Building\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(128,128,3)))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(128, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(2, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "xjdnjfVoB9c6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.summary()"
      ],
      "metadata": {
        "id": "7TpNjUlxWpqD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer='Adam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "KgQlQiN8aZ26"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience = 5)"
      ],
      "metadata": {
        "id": "ysP_xZeNeL_-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs = 20,\n",
        "    validation_data = (X_test,y_test),\n",
        "    callbacks=[early_stopping]\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtPVF9dyceX4",
        "outputId": "1c5e9074-b96e-4607-ce46-00e2fae32760"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "189/189 [==============================] - 16s 27ms/step - loss: 0.4930 - accuracy: 0.7749 - val_loss: 0.3717 - val_accuracy: 0.8637\n",
            "Epoch 2/20\n",
            "189/189 [==============================] - 4s 20ms/step - loss: 0.3067 - accuracy: 0.8757 - val_loss: 0.2465 - val_accuracy: 0.8974\n",
            "Epoch 3/20\n",
            "189/189 [==============================] - 4s 21ms/step - loss: 0.2502 - accuracy: 0.9042 - val_loss: 0.1992 - val_accuracy: 0.9173\n",
            "Epoch 4/20\n",
            "189/189 [==============================] - 3s 18ms/step - loss: 0.2190 - accuracy: 0.9167 - val_loss: 0.1952 - val_accuracy: 0.9219\n",
            "Epoch 5/20\n",
            "189/189 [==============================] - 3s 18ms/step - loss: 0.1929 - accuracy: 0.9230 - val_loss: 0.1902 - val_accuracy: 0.9226\n",
            "Epoch 6/20\n",
            "189/189 [==============================] - 4s 21ms/step - loss: 0.1617 - accuracy: 0.9356 - val_loss: 0.1627 - val_accuracy: 0.9358\n",
            "Epoch 7/20\n",
            "189/189 [==============================] - 3s 18ms/step - loss: 0.1443 - accuracy: 0.9439 - val_loss: 0.1831 - val_accuracy: 0.9312\n",
            "Epoch 8/20\n",
            "189/189 [==============================] - 4s 19ms/step - loss: 0.1287 - accuracy: 0.9523 - val_loss: 0.1734 - val_accuracy: 0.9358\n",
            "Epoch 9/20\n",
            "189/189 [==============================] - 3s 18ms/step - loss: 0.1033 - accuracy: 0.9593 - val_loss: 0.2339 - val_accuracy: 0.9239\n",
            "Epoch 10/20\n",
            "189/189 [==============================] - 4s 21ms/step - loss: 0.1037 - accuracy: 0.9631 - val_loss: 0.1872 - val_accuracy: 0.9378\n",
            "Epoch 11/20\n",
            "189/189 [==============================] - 3s 18ms/step - loss: 0.0844 - accuracy: 0.9695 - val_loss: 0.1630 - val_accuracy: 0.9457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model\n",
        "model.save('FaceMaskDetModel.h5')"
      ],
      "metadata": {
        "id": "QNUW3_xAm32m"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}